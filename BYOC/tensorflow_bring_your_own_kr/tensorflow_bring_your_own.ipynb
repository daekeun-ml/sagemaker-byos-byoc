{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BYOC TensorFlow(TensorFlow 커스텀 컨테이너 사용하기)\n",
    "\n",
    "***Note: 본 핸즈온은 SageMaker SDK V2에 대응하도록 코드를 수정했습니다. 만약 SDK V1용 코드가 필요하다면 아래 링크를 참조해 주십시오.***\n",
    "\n",
    "소스 : https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/tensorflow_bring_your_own/tensorflow_bring_your_own.ipynb\n",
    "\n",
    "Amazon SageMaker에서는 여러분의 알고리즘을 SageMaker 환경에서 학습하고 배포할 수 있도록 패키징할 수 있습니다. 본 노트북은 Tensorflow를 SageMaker환경에서 학습, 배포할 수 있도록 커스텀 도커 컨테이너로 빌드하는 방법을 알아봅니다.\n",
    "\n",
    "알고리즘을 컨테이너로 패키징함으로써, 프로그래밍 언어나 프레임워크, 의존관계 등과 무관하게 여러분의 코드를 SageMaker 환경에서 구동할 수 있게 됩니다. \n",
    "\n",
    "설명없이 코드로 바로 시작하시려면 __도커파일 (코드 시작)__ 섹션으로 바로 이동하십시오.  \n",
    "\n",
    "## 언제 커스텀 알고리즘 컨테이너를 사용해야 하나요?\n",
    "\n",
    "여러분의 코드를 SageMaker에서 구동하기 위하여 반드시 컨테이너를 직접 만들어야 하는 것은 아닙니다. 만약 여러분이 사용하는 프레임웤이 Apach MXNet이나 Tensorflow 등일 경우 SageMaker는 해당 프레임워크를 직접 지원하기 때문에 여러분은 알고리즘을 구현하는 파이썬 코드만 제공하고 이를 프레임워크 SDK의 entry point에 전달하여 활용할 수 있습니다. SageMaker에서 지원되는 프레임워크는 정기적으로 추가되고 있고, SageMaker에서 지원하는 범용 머신러닝 환경 리스트를 통해 여러분이 작성하시는 알고리즘의 환경이 SageMaker에서 지원되는 지를 확인할 수 있습니다. \n",
    "\n",
    "단, 여러분의 환경이나 프레임워크를 지원하는 SDK가 있다고 하더라도 커스텀 컨테이너를 직접 빌드하는 것이 보다 효과적일 경우도 있습니다. 여러분의 알고리즘 코드가 매우 복잡하거나 추가로 다른 프레임웤를 필요로 하는 경우에는 컨테이너를 직접 빌드하는 것이 적절한 선택일 수도 있습니다. 이런 경우에 해당하는 몇가지 사례는 다음과 같습니다. \n",
    "\n",
    "1. 프레임워크의 특정 버전이 지원되지 않는 경우\n",
    "2. 환경에 의존라이브러리들을 추가로 설치하고 설정하는 경우\n",
    "3. 기본 환경에서 제공되지 않는 학습/배포 솔루션을 사용하는 경우\n",
    "\n",
    "커스텀 컨테이너를 이용하면 SageMaker에서 사전 제공하지 않는 환경일 경우에도 SageMaker기반으로 동작하도록 할 수 있습니다. 본 예제에서 그 과정을 살펴보겠습니다. \n",
    "\n",
    "## 권한 설정\n",
    "\n",
    "본 노트북은 `SageMakerFullAccess`권한에 추가로 Amazon ECR에 접근하기 위한 권한이 필요합니다. 권한을 추가하는 가장 간단한 방법은 관리형 정책인 `AmazonEC2ContainerRegistryFullAccess`를 노트북 인스턴스가 사용중인 역할(role)에 추가하는 것입니다. 이를 위해 노트북 인스턴스를 재시작할 필요는 없으며 수정 즉시 새로운 권한이 할당 될 것입니다. \n",
    "\n",
    "\n",
    "## 샘플 시나리오\n",
    "\n",
    "본 예제에서는 CIFAR-10 데이터셋을 학습할 수 있는 커스텀 Tensorflow 컨테이너를 패키징하고 추론 환경은 Tensorflow Serving을 사용합니다. 하지만 본 예제를 일부 수정하면 Tensorflow Serving이 아닌 다른 추론 환경에도 응용할 수 있을 것입니다. \n",
    "\n",
    "[CIFAR-10]: http://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "본 예제에서는 학습과 추론 실행을 단일 이미지로 사용할 것입니다. 하나의 이미지로 학습과 추론을 실행하는 경우 하나의 이미지만 관리하면 되므로 관리절차가 단순해 집니다. 하지만 실제 요구사항에 따라 이 두 환경의 이미지가 분리될 수도 있을 것입니다. 이 경우 Dockerfile을 분리하고 두 개의 이미지를 운영하게 됩니다. 이미지의 분리와 통합은 실제 환경 요구사항과 개발 및 관리 편의성을 고려하여 결정합니다. \n",
    "\n",
    "그리고 SageMaker에서 학습과 추론을 모두 실행하지 않고 이 중 한가지 방식만 이용할 경우에는 해당 기능의 이미지만 빌드하면 됩니다.\n",
    "\n",
    "본 예제는 컨테이너를 __빌드__하는 부분과 __활용__하는 부분의 두 파트로 나누어져 있습니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: 알고리즘을 SageMaker환경으로 패키징하고 업로드하기 \n",
    "\n",
    "### 도커 개요\n",
    "\n",
    "만약 여러분이 이미 도커 환경이 친숙하다면 이 단계는 건너뛰고 다음 섹션으로 이동하십시오.\n",
    "\n",
    "많은 데이터 사이언티스트들에게 도커 컨테이너는 새로운 기술입니다. 하지만 도커는 여러분의 소프트웨어를 패키징하여 배포하는 매우 간편한 방법이며 그리 어렵지 않습니다. \n",
    "\n",
    "도커는 임의의 코드를 스스로 실행환경을 포함하는 __이미지__로 패키징하는 간단한 방법을 제공합니다. 이미지가 생성되고 나면, 도커 환경에서 이 이미지를 __컨테이너__로 실행하게 됩니다. 컨테이너를 실행하는 것은 컨테이너가 프로그램이 실행될 실행환경을 스스로 생성한다는 것을 제외하면 일반적으로 컴퓨터 머신에서 프로그램을 실행하는 것과 다르지 않습니다. 컨테이너는 호스트 환경에서 다른 컴퓨팅 환경과 격리됩니다. 이것은 이 컨테이너가 어디에 실행되는지에 관계없이 독자적인 실행방식을 구성할 수 있게 만들어 줍니다.\n",
    "\n",
    "도커는 다음과 같은 이유로 conda나 virtualenv와 같은 환경관리에 비해 매우 강력합니다. \n",
    "- 도커 환경은 프로그래밍 언에에 독립적입니다.\n",
    "- 초기 실행명령과 환경변수까지 전체 운영환경을 포괄합니다.\n",
    "\n",
    "도커 컨테이너는 가상머신과 유사하지만 보다 경령화되어 있습니다. 예를 들어, 컨테이너에서 실행되는 프로그램은 1초 이내에 시작될 수 있고 물리 또는 가상 서버 인스턴스에서 동시에 실행될 수 있습니다. \n",
    "\n",
    "도커는 `Dockerfile`이라는 간단한 파일을 사용하여 이미지가 구성되는 방식을 정의합니다. 그 사례는 아래에 제공됩니다. 여러분은 여러분이 만들거나 또는 다른 사람이 만든 도커 이미지를 기반으로 새로운 도커 이미지를 만들 수 있습니다. 이런 방식은 이미지의 생성을 매우 단순화시켜줍니다.\n",
    "\n",
    "도커는 이런 유연함과 함께 잘 정리된 컨테이너 설정방식을 제공하여 프로그래밍과 개발 커뮤니테에서 열광적인 환영을 받고 있으며, 최근 [Amazon ECS]나 [Amazon EKS]와 같은 많은 서비스가 이 기술을 기반으로 구현되고 제공되고 있습니다. \n",
    "\n",
    "Amazon SageMaker 또한 사용자가 임의의 알고리즘을 학습하고 배포할 때 이 도커를 이용합니다. \n",
    "\n",
    "Amazon SageMaker 에서 도커 컨테이너는 학습을 위한 방식과, 학습과는 조금 다른 추론 호스팅의 방식으로 호출(invoke) 됩니다. 다음 섹션에서 SageMaker 환경에서 컨테이너를 어떻게 빌드하는지에 대해 설명합니다. \n",
    "\n",
    "도커와 관련한 보다 자세한 내용은 아래 링크를 참고하십시오. \n",
    "\n",
    "* [Docker home page](http://www.docker.com)\n",
    "* [Getting started with Docker](https://docs.docker.com/get-started/)\n",
    "* [Dockerfile reference](https://docs.docker.com/engine/reference/builder/)\n",
    "* [`docker run` reference](https://docs.docker.com/engine/reference/run/)\n",
    "\n",
    "[Amazon ECS]: https://aws.amazon.com/ecs/\n",
    "[Amazon EKS]: https://aws.amazon.com/eks/\n",
    "\n",
    "### Amazon SageMaker 에서 도커 컨테이너 실행 방식 \n",
    "\n",
    "SageMaker에서 학습과 호스팅에 동일한 이미지를 사용할 수 있으며, 컨테이너를 실행시 `train` 또는 `serve`라는 매개변수(argument)를 이용하여 컨테이너를 실행합니다. 컨테이너가 이 매개변수를 처리하는 방식은 컨테이너 구성에 따라 달라집니다.\n",
    "\n",
    "* 본 샘플에서는 도커파일(Dokerfile)에서 `ENTRYPOINT`를 사용하지 않습니다. 대신 학습시점에는 [`train`](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html) 명령을 서빙(호스팅)시점에는 [`serve`](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html) 명령을 이용하여 도커를 실행합니다.\n",
    "* 만약 도커파일에서 `ENTRYPOINT`를 이용하여 프로그램을 명시하게 되면 도커 실행시 해당프로그램이 실행되며 `train` 또는 `serve`가 첫번째 매개변수로 전달될 것입니다. 프로그램은 이 매개변수에 따라 무슨 동작을 해야할 지를 판단할 수 있습니다. \n",
    "* 만약 학습과 호스팅 컨테이너를 분리하는 경우 (또는 둘 장 하나의 방식만 활용하는 경우) 도커파일에 `ENTRYPOINT`에 프로그램을 정의할 수 있고, 이 때 전달되는 첫번째 매개변수는 무시하거나 또는 검증용으로 사용할 수 있습니다. \n",
    "\n",
    "\n",
    "#### 학습(training)용으로 커스텀 컨테이너 이용하기 \n",
    "\n",
    "SageMaker에서 학습이 실행될 때 여러분의 `train` 스크립트가 실행됩니다. 일반적인 파이썬 프로그램이 실행되는 것과 마찬가지 방식이며, `/opt/ml` 디렉토리의 몇가지 파일들이 활용될 수 있습니다.\n",
    "\n",
    "    /opt/ml\n",
    "    |-- input\n",
    "    |   |-- config\n",
    "    |   |   |-- hyperparameters.json\n",
    "    |   |   `-- resourceConfig.json\n",
    "    |   `-- data\n",
    "    |       `-- <channel_name>\n",
    "    |           `-- <input data>\n",
    "    |-- model\n",
    "    |   `-- <model files>\n",
    "    `-- output\n",
    "        `-- failure\n",
    "\n",
    "##### 데이터 입력\n",
    "\n",
    "* `/opt/ml/input/config` - 프로그램이 실행되는 방식을 관리할 수 있는 정보가 포함됩니다. `hyperparameters.json` 은 하이퍼파라미터 이름과 값을 가지는 JSON 형식의 딕셔너리입니다. 값은 string 형태로 전달되며 필요시 타입을 변환하여 사용합니다. `resourceConfig.json` 은 분산학습에서 네트워크 레이아웃을 알려주는 JSON형식의 파일입니다. \n",
    "\n",
    "* `/opt/ml/input/data/<channel_name>/` - (파일 모드일 경우) 채널에 대한 입력데이터가 저장됩니다. 채널은 CreateTrainingJob(또는 fit)을 호출할 때 생성되며 알고리즘 코드에서 동일하게 사용해야 합니다. 알고리즘에서 사용할 파일들이 S3로부터 지정한 채널로 복사되며 S3 키의 트리 구조를 유지합니다. \n",
    "\n",
    "* `/opt/ml/input/data/<channel_name>_<epoch_number>` (파이프 모드일 경우) 실행되는 epoch을 위한 파이프입니다. epoch은 0에서부터 이 채널을 읽을때마다 증가합니다. epoch숫자에 제한은 없으며 다음 epoch을 실행하기 전에 pipe를 close 해야 합니다. \n",
    "\n",
    "\n",
    "##### 학습결과 출력\n",
    "\n",
    "* `/opt/ml/model/` - 알고리즘이 생성하는 모델이 저장되는 디렉토리입니다. 모델의 형식은 여러분이 지정하는 방식에 따라 달라지며, 단일 파일일 수도 있고 트리구조를 가지는 디렉토리 전체일 수도 있습니다. 모델 파일은 `DescribeTrainingJob` 호출 결과로 리턴되는 지정된 S3 위치에 사용가능하도록 export 됩니다. \n",
    "\n",
    "* `/opt/ml/output` - 작업이 실패할 때 `failure` 파일을 저장하는 디렉토리입니다. 파일의 내용은 `DescribeTrainingJob`호출시 `FailureReason` 필드의 값으로 리턴됩니다. 작업이 성공적으로 종료될 경우 이 파일은 필요가 없으므로 무시됩니다. \n",
    "\n",
    "\n",
    "#### 호스팅(추론)용으로 컨테이너 이용하기\n",
    "\n",
    "추론 호스팅은 HTTP를 통해 들어오는 추론 요청(request)에 응답해야 하므로 학습과는 다른 모델을 가집니다. 본 사례에서는 [TensorFlow Serving](https://www.tensorflow.org/serving/)을 사용하지만 이는 다른 환경으로 커스터마이징될 수도 있습니다. [Python serving stack within the scikit learn example](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb)과 같은 사례를 참고하십시오. \n",
    "\n",
    "Amazon SageMaker 추론 컨테이너 내부에서는 다음 두가지 URL을 사용합니다. \n",
    "\n",
    "* `/ping` - 인프라로부터 `GET` 요청을 받아서 처리합니다. 컨테이너가 정상적으로 동작하고 요청을 받을 수 있는 경우 200을 리턴합니다.\n",
    "* `/invocations` - 추론 클라이언트로부터 `POST`요청을 받아 처리합니다. 요청과 응답의 형식은 알고리즘에 따라 달라집니다. 클라이언트가 `ContentType`과 `Accept` 헤더를 지정한 경우 함께 전달됩니다.\n",
    "\n",
    "추론 컨테이너의 모델 파일 위치는 학습에서 생성한 모델을 저장할 때 사용한 위치와 동일합니다. \n",
    "\n",
    "    /opt/ml\n",
    "    `-- model\n",
    "        `-- <model files>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parts of the sample container\n",
    "\n",
    "본 예제의 `container` 디렉토리에 샘플 알고리즘을 SageMaker환경으로 패키징하는 모든 파일들이 저장되어 있습니다.\n",
    "\n",
    "    .\n",
    "    |-- Dockerfile\n",
    "    |-- build_and_push.sh\n",
    "    `-- cifar10\n",
    "        |-- cifar10.py\n",
    "        |-- resnet_model.py\n",
    "        |-- nginx.conf\n",
    "        |-- serve\n",
    "        `-- train\n",
    "\n",
    "이들 파일을 차례로 살펴보면:\n",
    "\n",
    "* __`Dockerfile`__ - 도커 컨테이너 이미지를 빌드하는 방법이 정의됩니다. 다음 섹션에서 다시 설명합니다. \n",
    "* __`build_and_push.sh`__ - Dockerfile을 이용하여 컨테이너 이미지를 빌드하고 ECR로 push하는 스크립트입니다. 본 노트북에서 이 쉘을 직접 실행할 것입니다. 이후 여러분의 알고리즘에 적용할 경우에도 이 파일을 그대로 사용할 수 있습니다. \n",
    "* __`cifar10`__ - 컨테이너 내부로 복제될 파일들이 저장되어 있습니다. \n",
    "\n",
    "본 예제에서 우리는 5개의 파일을 컨테이너로 복제할 것입니다. 실제로는 여러분의 유즈케이스에 따라 이정도의 파일이 충분할 수도 있고 또는 더 많은 파일이 필요할 수도 있습니다. 하지만 이 5개의 파일이 커스텀 파이썬 컨테이너의 표준 구조가 됩니다. 물론 예제코드와 다른 도구(toolkit)를 사용할 경우에는 다른 구조가 될 수도 있습니다. 본 예제는 Tensorflow serving과 nginx를 사용하지만 다른 프로그래밍 언어나 프레임워크를 사용하는 경우 다른 구성을 가질 것입니다. \n",
    "\n",
    "본 예제에서 컨테이너에 복제될 파일은 다음과 같습니다. (`cifar10`디렉토리 내부의 파일들)\n",
    "\n",
    "* __`cifar10.py`__ - 알고리즘의 실행을 구현하는 프로그램 코드입니다. \n",
    "* __`resnet_model.py`__ - Resnet 모델을 정의하는 코드입니다. (`cifar10.py`에서 사용합니다.)\n",
    "* __`nginx.conf`__ - nginx front-end를 구성하는 설정 파일입니다. 일반적으로 제공되는 파일을 그대로 사용가능합니다.\n",
    "* __`serve`__ - 컨테이너가 추론 호스팅을 할 때 실행되는 프로그램입니다. nginx를 실행하고 Tensorflow serving에 모델을 로드합니다. \n",
    "* __`train`__ - 컨테이너가 학습을 진행할 때 실행되는 프로그램입니다. 본 예제에서는 /opt/ml/input/config/hyperparameters.json로 입력된 하이퍼파라미터를 이용하여 `cifar10.py` 를 호출(invoke)할 것입니다. 이런 구조를 통해 학습알고리즘과 컨테이너 실행코드를 독립적으로 분리하여 관리합니다.\n",
    "\n",
    "요약하면, 이후 여러분의 실제 애플리케이션에 여러분의 알고리즘 실행코드를 적용할 때에는 해당 코드와 함께 `train`과 `serve` 부분을 변경하게 됩니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도커파일 (코드 시작)\n",
    "\n",
    "Dockerfile은 빌드할 이미지를 정의합니다. 실행할 시스템의 운영체제와 환경을 완전히 정의하는 것으로 생각해도 좋습니다. 하지만 실제로 도커 컨테이너의 실행은 운영체제를 모두 준비하는 것에 비해 매우 경량화되어 있으며 기초 동작은 호스트머신의 Linux를 활용합니다. \n",
    "\n",
    "파이선 데이터사이언스 스택을 준비하기 위해 Tensorflow docker 이미지로 부터 시작하하여 기본 도구와 Tensorflow serving을 설치하겠습니다. 그리고 이 환경에서 실행될 사용자 알고리즘 코드를 추가하겠습니다. \n",
    "\n",
    "아래 코드를 이용하여 Dockerfile을 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2017-2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\r\n",
      "#\r\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\"). You\r\n",
      "# may not use this file except in compliance with the License. A copy of\r\n",
      "# the License is located at\r\n",
      "#\r\n",
      "#     http://aws.amazon.com/apache2.0/\r\n",
      "#\r\n",
      "# or in the \"license\" file accompanying this file. This file is\r\n",
      "# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\r\n",
      "# ANY KIND, either express or implied. See the License for the specific\r\n",
      "# language governing permissions and limitations under the License.\r\n",
      "\r\n",
      "# For more information on creating a Dockerfile\r\n",
      "# https://docs.docker.com/compose/gettingstarted/#step-2-create-a-dockerfile\r\n",
      "FROM tensorflow/tensorflow:1.8.0-py3\r\n",
      "\r\n",
      "RUN apt-get update && apt-get install -y --no-install-recommends nginx curl\r\n",
      "\r\n",
      "# Download TensorFlow Serving\r\n",
      "# https://www.tensorflow.org/serving/setup#installing_the_modelserver\r\n",
      "RUN echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list\r\n",
      "RUN curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\r\n",
      "RUN apt-get update && apt-get install tensorflow-model-server\r\n",
      "\r\n",
      "ENV PATH=\"/opt/ml/code:${PATH}\"\r\n",
      "\r\n",
      "# /opt/ml and all subdirectories are utilized by SageMaker, we use the /code subdirectory to store our user code.\r\n",
      "COPY /cifar10 /opt/ml/code\r\n",
      "WORKDIR /opt/ml/code"
     ]
    }
   ],
   "source": [
    "!cat container/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨테이너 빌드 및 등록\n",
    "\n",
    "다음 쉘스크립트는 `docker build` 명령을 이용하여 컨테이너를 빌드하고 `docker push`명령을 이용하여 ECR에 빌드한 이미지를 push하는 방법을 보여줍니다. 해당 코드는 `container/build-and-push.sh`의 내용과 동일하며 `sagemaker-tf-cifar10-example`라는 이름으로 이미지를 빌드하고 push 하고자 할 때 `build-and-push.sh sagemaker-tf-cifar10-example`와 같은 형식으로 실행하면 됩니다.\n",
    "\n",
    "아래 코드는 여러분의 어카운트의 디폴트 리전 (또는 SageMaker 노트북 인스턴스를 사용중인 경우 노트북이 생성된 리전)에서 ECR 레포지토리를 찾고, 만약 레포지토리가 없다면 이를 생성할 것입니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  35.84kB\r",
      "\r\n",
      "Step 1/8 : FROM tensorflow/tensorflow:1.8.0-py3\n",
      "1.8.0-py3: Pulling from tensorflow/tensorflow\n",
      "297061f60c36: Pulling fs layer\n",
      "e9ccef17b516: Pulling fs layer\n",
      "dbc33716854d: Pulling fs layer\n",
      "8fe36b178d25: Pulling fs layer\n",
      "686596545a94: Pulling fs layer\n",
      "11251ff8ca17: Pulling fs layer\n",
      "632ad5221740: Pulling fs layer\n",
      "c61bc0eaf8d9: Pulling fs layer\n",
      "f5e02d7ae67a: Pulling fs layer\n",
      "f29a5775b72a: Pulling fs layer\n",
      "c9bf16bc9d22: Pulling fs layer\n",
      "d4423e297b68: Pulling fs layer\n",
      "418a4217796d: Pulling fs layer\n",
      "02b18d984060: Pulling fs layer\n",
      "686596545a94: Waiting\n",
      "c9bf16bc9d22: Waiting\n",
      "c61bc0eaf8d9: Waiting\n",
      "11251ff8ca17: Waiting\n",
      "d4423e297b68: Waiting\n",
      "418a4217796d: Waiting\n",
      "f29a5775b72a: Waiting\n",
      "632ad5221740: Waiting\n",
      "f5e02d7ae67a: Waiting\n",
      "02b18d984060: Waiting\n",
      "8fe36b178d25: Waiting\n",
      "e9ccef17b516: Verifying Checksum\n",
      "e9ccef17b516: Download complete\n",
      "dbc33716854d: Verifying Checksum\n",
      "dbc33716854d: Download complete\n",
      "8fe36b178d25: Verifying Checksum\n",
      "8fe36b178d25: Download complete\n",
      "686596545a94: Verifying Checksum\n",
      "686596545a94: Download complete\n",
      "632ad5221740: Verifying Checksum\n",
      "632ad5221740: Download complete\n",
      "297061f60c36: Verifying Checksum\n",
      "297061f60c36: Download complete\n",
      "f5e02d7ae67a: Verifying Checksum\n",
      "f5e02d7ae67a: Download complete\n",
      "297061f60c36: Pull complete\n",
      "c61bc0eaf8d9: Verifying Checksum\n",
      "c61bc0eaf8d9: Download complete\n",
      "e9ccef17b516: Pull complete\n",
      "c9bf16bc9d22: Verifying Checksum\n",
      "c9bf16bc9d22: Download complete\n",
      "d4423e297b68: Download complete\n",
      "dbc33716854d: Pull complete\n",
      "8fe36b178d25: Pull complete\n",
      "f29a5775b72a: Verifying Checksum\n",
      "f29a5775b72a: Download complete\n",
      "686596545a94: Pull complete\n",
      "11251ff8ca17: Verifying Checksum\n",
      "11251ff8ca17: Download complete\n",
      "02b18d984060: Verifying Checksum\n",
      "02b18d984060: Download complete\n",
      "418a4217796d: Verifying Checksum\n",
      "418a4217796d: Download complete\n",
      "11251ff8ca17: Pull complete\n",
      "632ad5221740: Pull complete\n",
      "c61bc0eaf8d9: Pull complete\n",
      "f5e02d7ae67a: Pull complete\n",
      "f29a5775b72a: Pull complete\n",
      "c9bf16bc9d22: Pull complete\n",
      "d4423e297b68: Pull complete\n",
      "418a4217796d: Pull complete\n",
      "02b18d984060: Pull complete\n",
      "Digest: sha256:24b533d6db08369375f85b7d8da0e7d8c35c105337a7f6fa71947195b900eec9\n",
      "Status: Downloaded newer image for tensorflow/tensorflow:1.8.0-py3\n",
      " ---> a83a3dd79ff9\n",
      "Step 2/8 : RUN apt-get update && apt-get install -y --no-install-recommends nginx curl\n",
      " ---> Running in 1f143906c608\n",
      "Get:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [109 kB]\n",
      "Get:2 http://security.ubuntu.com/ubuntu xenial-security/universe Sources [256 kB]\n",
      "Get:3 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [1988 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu xenial InRelease [247 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu xenial-security/restricted amd64 Packages [15.9 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [984 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [8820 B]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu xenial/universe Sources [9802 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu xenial/main amd64 Packages [1558 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu xenial/restricted amd64 Packages [14.1 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu xenial/universe amd64 Packages [9827 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu xenial/multiverse amd64 Packages [176 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu xenial-updates/universe Sources [548 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages [2498 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu xenial-updates/restricted amd64 Packages [16.4 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu xenial-updates/universe amd64 Packages [1540 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu xenial-updates/multiverse amd64 Packages [26.2 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu xenial-backports/main amd64 Packages [10.9 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu xenial-backports/universe amd64 Packages [12.6 kB]\n",
      "Fetched 29.9 MB in 3s (9097 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  fontconfig-config fonts-dejavu-core libcurl3-gnutls libfontconfig1 libgd3\n",
      "  libgeoip1 libicu55 libjbig0 libjpeg-turbo8 libjpeg8 libtiff5 libvpx3\n",
      "  libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 libxml2 libxpm4 libxslt1.1\n",
      "  nginx-common nginx-core ucf\n",
      "Suggested packages:\n",
      "  libgd-tools geoip-bin fcgiwrap nginx-doc ssl-cert\n",
      "Recommended packages:\n",
      "  geoip-database xml-core\n",
      "The following NEW packages will be installed:\n",
      "  fontconfig-config fonts-dejavu-core libfontconfig1 libgd3 libgeoip1 libicu55\n",
      "  libjbig0 libjpeg-turbo8 libjpeg8 libtiff5 libvpx3 libx11-6 libx11-data\n",
      "  libxau6 libxcb1 libxdmcp6 libxml2 libxpm4 libxslt1.1 nginx nginx-common\n",
      "  nginx-core ucf\n",
      "The following packages will be upgraded:\n",
      "  curl libcurl3-gnutls\n",
      "2 upgraded, 23 newly installed, 0 to remove and 114 not upgraded.\n",
      "Need to get 12.5 MB of archives.\n",
      "After this operation, 46.4 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxau6 amd64 1:1.0.8-1 [8376 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libjpeg-turbo8 amd64 1.4.2-0ubuntu3.4 [111 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu xenial/main amd64 libjbig0 amd64 2.1-3.1 [26.6 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu xenial/main amd64 ucf all 3.0036 [52.9 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 curl amd64 7.47.0-1ubuntu2.18 [139 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libcurl3-gnutls amd64 7.47.0-1ubuntu2.18 [184 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu xenial/main amd64 libgeoip1 amd64 1.6.9-1 [70.1 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libicu55 amd64 55.1-7ubuntu0.5 [7650 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxdmcp6 amd64 1:1.1.2-1.1 [11.0 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxcb1 amd64 1.11.1-1ubuntu1 [40.0 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libx11-data all 2:1.6.3-1ubuntu2.2 [114 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libx11-6 amd64 2:1.6.3-1ubuntu2.2 [572 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libxml2 amd64 2.9.3+dfsg1-1ubuntu0.7 [698 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu xenial/main amd64 fonts-dejavu-core all 2.35-1 [1039 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 fontconfig-config all 2.11.94-0ubuntu1.1 [49.9 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libfontconfig1 amd64 2.11.94-0ubuntu1.1 [131 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu xenial/main amd64 libjpeg8 amd64 8c-2ubuntu8 [2194 B]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libtiff5 amd64 4.0.6-1ubuntu0.8 [149 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libvpx3 amd64 1.5.0-2ubuntu1.1 [732 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libxpm4 amd64 1:3.5.11-1ubuntu0.16.04.1 [33.8 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libgd3 amd64 2.1.1-4ubuntu0.16.04.12 [126 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libxslt1.1 amd64 1.1.28-2.1ubuntu0.3 [146 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 nginx-common all 1.10.3-0ubuntu0.16.04.5 [26.9 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 nginx-core amd64 1.10.3-0ubuntu0.16.04.5 [429 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 nginx all 1.10.3-0ubuntu0.16.04.5 [3494 B]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 12.5 MB in 1s (10.3 MB/s)\n",
      "Selecting previously unselected package libxau6:amd64.\r\n",
      "(Reading database ... \r",
      "(Reading database ... 5%\r",
      "(Reading database ... 10%\r",
      "(Reading database ... 15%\r",
      "(Reading database ... 20%\r",
      "(Reading database ... 25%\r",
      "(Reading database ... 30%\r",
      "(Reading database ... 35%\r",
      "(Reading database ... 40%\r",
      "(Reading database ... 45%\r",
      "(Reading database ... 50%\r",
      "(Reading database ... 55%\r",
      "(Reading database ... 60%\r",
      "(Reading database ... 65%\r",
      "(Reading database ... 70%\r",
      "(Reading database ... 75%\r",
      "(Reading database ... 80%\r",
      "(Reading database ... 85%\r",
      "(Reading database ... 90%\r",
      "(Reading database ... 95%\r",
      "(Reading database ... 100%\r",
      "(Reading database ... 12490 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libxau6_1%3a1.0.8-1_amd64.deb ...\r\n",
      "Unpacking libxau6:amd64 (1:1.0.8-1) ...\r\n",
      "Selecting previously unselected package libjpeg-turbo8:amd64.\r\n",
      "Preparing to unpack .../libjpeg-turbo8_1.4.2-0ubuntu3.4_amd64.deb ...\r\n",
      "Unpacking libjpeg-turbo8:amd64 (1.4.2-0ubuntu3.4) ...\r\n",
      "Selecting previously unselected package libjbig0:amd64.\r\n",
      "Preparing to unpack .../libjbig0_2.1-3.1_amd64.deb ...\r\n",
      "Unpacking libjbig0:amd64 (2.1-3.1) ...\r\n",
      "Selecting previously unselected package ucf.\r\n",
      "Preparing to unpack .../archives/ucf_3.0036_all.deb ...\r\n",
      "Moving old data out of the way\r\n",
      "Unpacking ucf (3.0036) ...\r\n",
      "Preparing to unpack .../curl_7.47.0-1ubuntu2.18_amd64.deb ...\r\n",
      "Unpacking curl (7.47.0-1ubuntu2.18) over (7.47.0-1ubuntu2.7) ...\r\n",
      "Preparing to unpack .../libcurl3-gnutls_7.47.0-1ubuntu2.18_amd64.deb ...\r\n",
      "Unpacking libcurl3-gnutls:amd64 (7.47.0-1ubuntu2.18) over (7.47.0-1ubuntu2.7) ...\r\n",
      "Selecting previously unselected package libgeoip1:amd64.\r\n",
      "Preparing to unpack .../libgeoip1_1.6.9-1_amd64.deb ...\r\n",
      "Unpacking libgeoip1:amd64 (1.6.9-1) ...\r\n",
      "Selecting previously unselected package libicu55:amd64.\r\n",
      "Preparing to unpack .../libicu55_55.1-7ubuntu0.5_amd64.deb ...\r\n",
      "Unpacking libicu55:amd64 (55.1-7ubuntu0.5) ...\r\n",
      "Selecting previously unselected package libxdmcp6:amd64.\r\n",
      "Preparing to unpack .../libxdmcp6_1%3a1.1.2-1.1_amd64.deb ...\r\n",
      "Unpacking libxdmcp6:amd64 (1:1.1.2-1.1) ...\r\n",
      "Selecting previously unselected package libxcb1:amd64.\r\n",
      "Preparing to unpack .../libxcb1_1.11.1-1ubuntu1_amd64.deb ...\r\n",
      "Unpacking libxcb1:amd64 (1.11.1-1ubuntu1) ...\r\n",
      "Selecting previously unselected package libx11-data.\r\n",
      "Preparing to unpack .../libx11-data_2%3a1.6.3-1ubuntu2.2_all.deb ...\r\n",
      "Unpacking libx11-data (2:1.6.3-1ubuntu2.2) ...\r\n",
      "Selecting previously unselected package libx11-6:amd64.\r\n",
      "Preparing to unpack .../libx11-6_2%3a1.6.3-1ubuntu2.2_amd64.deb ...\r\n",
      "Unpacking libx11-6:amd64 (2:1.6.3-1ubuntu2.2) ...\r\n",
      "Selecting previously unselected package libxml2:amd64.\r\n",
      "Preparing to unpack .../libxml2_2.9.3+dfsg1-1ubuntu0.7_amd64.deb ...\r\n",
      "Unpacking libxml2:amd64 (2.9.3+dfsg1-1ubuntu0.7) ...\r\n",
      "Selecting previously unselected package fonts-dejavu-core.\r\n",
      "Preparing to unpack .../fonts-dejavu-core_2.35-1_all.deb ...\r\n",
      "Unpacking fonts-dejavu-core (2.35-1) ...\r\n",
      "Selecting previously unselected package fontconfig-config.\r\n",
      "Preparing to unpack .../fontconfig-config_2.11.94-0ubuntu1.1_all.deb ...\r\n",
      "Unpacking fontconfig-config (2.11.94-0ubuntu1.1) ...\r\n",
      "Selecting previously unselected package libfontconfig1:amd64.\r\n",
      "Preparing to unpack .../libfontconfig1_2.11.94-0ubuntu1.1_amd64.deb ...\r\n",
      "Unpacking libfontconfig1:amd64 (2.11.94-0ubuntu1.1) ...\r\n",
      "Selecting previously unselected package libjpeg8:amd64.\r\n",
      "Preparing to unpack .../libjpeg8_8c-2ubuntu8_amd64.deb ...\r\n",
      "Unpacking libjpeg8:amd64 (8c-2ubuntu8) ...\r\n",
      "Selecting previously unselected package libtiff5:amd64.\r\n",
      "Preparing to unpack .../libtiff5_4.0.6-1ubuntu0.8_amd64.deb ...\r\n",
      "Unpacking libtiff5:amd64 (4.0.6-1ubuntu0.8) ...\r\n",
      "Selecting previously unselected package libvpx3:amd64.\r\n",
      "Preparing to unpack .../libvpx3_1.5.0-2ubuntu1.1_amd64.deb ...\r\n",
      "Unpacking libvpx3:amd64 (1.5.0-2ubuntu1.1) ...\r\n",
      "Selecting previously unselected package libxpm4:amd64.\r\n",
      "Preparing to unpack .../libxpm4_1%3a3.5.11-1ubuntu0.16.04.1_amd64.deb ...\r\n",
      "Unpacking libxpm4:amd64 (1:3.5.11-1ubuntu0.16.04.1) ...\r\n",
      "Selecting previously unselected package libgd3:amd64.\r\n",
      "Preparing to unpack .../libgd3_2.1.1-4ubuntu0.16.04.12_amd64.deb ...\r\n",
      "Unpacking libgd3:amd64 (2.1.1-4ubuntu0.16.04.12) ...\r\n",
      "Selecting previously unselected package libxslt1.1:amd64.\r\n",
      "Preparing to unpack .../libxslt1.1_1.1.28-2.1ubuntu0.3_amd64.deb ...\r\n",
      "Unpacking libxslt1.1:amd64 (1.1.28-2.1ubuntu0.3) ...\r\n",
      "Selecting previously unselected package nginx-common.\r\n",
      "Preparing to unpack .../nginx-common_1.10.3-0ubuntu0.16.04.5_all.deb ...\r\n",
      "Unpacking nginx-common (1.10.3-0ubuntu0.16.04.5) ...\r\n",
      "Selecting previously unselected package nginx-core.\r\n",
      "Preparing to unpack .../nginx-core_1.10.3-0ubuntu0.16.04.5_amd64.deb ...\r\n",
      "Unpacking nginx-core (1.10.3-0ubuntu0.16.04.5) ...\r\n",
      "Selecting previously unselected package nginx.\r\n",
      "Preparing to unpack .../nginx_1.10.3-0ubuntu0.16.04.5_all.deb ...\r\n",
      "Unpacking nginx (1.10.3-0ubuntu0.16.04.5) ...\r\n",
      "Processing triggers for libc-bin (2.23-0ubuntu10) ...\r\n",
      "Processing triggers for systemd (229-4ubuntu21.2) ...\r\n",
      "Setting up libxau6:amd64 (1:1.0.8-1) ...\r\n",
      "Setting up libjpeg-turbo8:amd64 (1.4.2-0ubuntu3.4) ...\r\n",
      "Setting up libjbig0:amd64 (2.1-3.1) ...\r\n",
      "Setting up ucf (3.0036) ...\r\n",
      "debconf: unable to initialize frontend: Dialog\r\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\r\n",
      "debconf: falling back to frontend: Readline\r\n",
      "Setting up libcurl3-gnutls:amd64 (7.47.0-1ubuntu2.18) ...\r\n",
      "Setting up curl (7.47.0-1ubuntu2.18) ...\r\n",
      "Setting up libgeoip1:amd64 (1.6.9-1) ...\r\n",
      "Setting up libicu55:amd64 (55.1-7ubuntu0.5) ...\r\n",
      "Setting up libxdmcp6:amd64 (1:1.1.2-1.1) ...\r\n",
      "Setting up libxcb1:amd64 (1.11.1-1ubuntu1) ...\r\n",
      "Setting up libx11-data (2:1.6.3-1ubuntu2.2) ...\r\n",
      "Setting up libx11-6:amd64 (2:1.6.3-1ubuntu2.2) ...\r\n",
      "Setting up libxml2:amd64 (2.9.3+dfsg1-1ubuntu0.7) ...\r\n",
      "Setting up fonts-dejavu-core (2.35-1) ...\r\n",
      "Setting up fontconfig-config (2.11.94-0ubuntu1.1) ...\r\n",
      "Setting up libfontconfig1:amd64 (2.11.94-0ubuntu1.1) ...\r\n",
      "Setting up libjpeg8:amd64 (8c-2ubuntu8) ...\r\n",
      "Setting up libtiff5:amd64 (4.0.6-1ubuntu0.8) ...\r\n",
      "Setting up libvpx3:amd64 (1.5.0-2ubuntu1.1) ...\r\n",
      "Setting up libxpm4:amd64 (1:3.5.11-1ubuntu0.16.04.1) ...\r\n",
      "Setting up libgd3:amd64 (2.1.1-4ubuntu0.16.04.12) ...\r\n",
      "Setting up libxslt1.1:amd64 (1.1.28-2.1ubuntu0.3) ...\r\n",
      "Setting up nginx-common (1.10.3-0ubuntu0.16.04.5) ...\r\n",
      "debconf: unable to initialize frontend: Dialog\r\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\r\n",
      "debconf: falling back to frontend: Readline\r\n",
      "Setting up nginx-core (1.10.3-0ubuntu0.16.04.5) ...\r\n",
      "invoke-rc.d: could not determine current runlevel\r\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\r\n",
      "Setting up nginx (1.10.3-0ubuntu0.16.04.5) ...\r\n",
      "Processing triggers for libc-bin (2.23-0ubuntu10) ...\r\n",
      "Processing triggers for systemd (229-4ubuntu21.2) ...\r\n",
      "Removing intermediate container 1f143906c608\n",
      " ---> a79e9df38cac\n",
      "Step 3/8 : RUN echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list\n",
      " ---> Running in 0eb4e837fa82\n",
      "deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
      "Removing intermediate container 0eb4e837fa82\n",
      " ---> a5be121d0b81\n",
      "Step 4/8 : RUN curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
      " ---> Running in 96c41dc02e3e\n",
      "\u001b[91m  % Total    % Received % Xferd  Averag\u001b[0m\u001b[91me Speed   Time \u001b[0m\u001b[91m   Time     Time  Current\n",
      "                 \u001b[0m\u001b[91m                Dlo\u001b[0m\u001b[91mad  Upload   Total \u001b[0m\u001b[91m  Spent\u001b[0m\u001b[91m    Left\u001b[0m\u001b[91m  Spee\u001b[0m\u001b[91md\n",
      "\r",
      "  0   \u001b[0m\u001b[91m  0    0    \u001b[0m\u001b[91m 0    0   \u001b[0m\u001b[91m  0 \u001b[0m\u001b[91m     0   \u001b[0m\u001b[91m   0 --:\u001b[0m\u001b[91m-\u001b[0m\u001b[91m-:-- --:--:\u001b[0m\u001b[91m-- --:--:--     0\u001b[0m\u001b[91m\r",
      "100  2943  100  2943    0     0  14624      0 --:--:-- --:--:-- --:--:-- 14641\n",
      "\u001b[0mOK\n",
      "Removing intermediate container 96c41dc02e3e\n",
      " ---> 9699551e11e3\n",
      "Step 5/8 : RUN apt-get update && apt-get install tensorflow-model-server\n",
      " ---> Running in c1d14e3a0d34\n",
      "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3012 B]\n",
      "Hit:2 http://security.ubuntu.com/ubuntu xenial-security InRelease\n",
      "Get:3 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [340 B]\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu xenial InRelease\n",
      "Get:5 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [348 B]\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu xenial-updates InRelease\n",
      "Hit:7 http://archive.ubuntu.com/ubuntu xenial-backports InRelease\n",
      "Fetched 3700 B in 0s (10.2 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following NEW packages will be installed:\n",
      "  tensorflow-model-server\n",
      "0 upgraded, 1 newly installed, 0 to remove and 114 not upgraded.\n",
      "Need to get 223 MB of archives.\n",
      "After this operation, 0 B of additional disk space will be used.\n",
      "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.4.1 [223 MB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 223 MB in 3s (55.9 MB/s)\n",
      "Selecting previously unselected package tensorflow-model-server.\r\n",
      "(Reading database ... \r",
      "(Reading database ... 5%\r",
      "(Reading database ... 10%\r",
      "(Reading database ... 15%\r",
      "(Reading database ... 20%\r",
      "(Reading database ... 25%\r",
      "(Reading database ... 30%\r",
      "(Reading database ... 35%\r",
      "(Reading database ... 40%\r",
      "(Reading database ... 45%\r",
      "(Reading database ... 50%\r",
      "(Reading database ... 55%\r",
      "(Reading database ... 60%\r",
      "(Reading database ... 65%\r",
      "(Reading database ... 70%\r",
      "(Reading database ... 75%\r",
      "(Reading database ... 80%\r",
      "(Reading database ... 85%\r",
      "(Reading database ... 90%\r",
      "(Reading database ... 95%\r",
      "(Reading database ... 100%\r",
      "(Reading database ... 13057 files and directories currently installed.)\r\n",
      "Preparing to unpack .../tensorflow-model-server_2.4.1_all.deb ...\r\n",
      "Unpacking tensorflow-model-server (2.4.1) ...\r\n",
      "Setting up tensorflow-model-server (2.4.1) ...\r\n",
      "Removing intermediate container c1d14e3a0d34\n",
      " ---> c7a4f454d6f3\n",
      "Step 6/8 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Running in df0eb5f4c5e1\n",
      "Removing intermediate container df0eb5f4c5e1\n",
      " ---> 74d54d62281f\n",
      "Step 7/8 : COPY /cifar10 /opt/ml/code\n",
      " ---> a858da43ad9a\n",
      "Step 8/8 : WORKDIR /opt/ml/code\n",
      " ---> Running in dd68ca555226\n",
      "Removing intermediate container dd68ca555226\n",
      " ---> 49e0cb6228b7\n",
      "Successfully built 49e0cb6228b7\n",
      "Successfully tagged sagemaker-tf-cifar10-example:latest\n",
      "The push refers to repository [143656149352.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tf-cifar10-example]\n",
      "cb97ce23f2f2: Preparing\n",
      "6b9c0da0c008: Preparing\n",
      "ae040751a676: Preparing\n",
      "613ece60d6b2: Preparing\n",
      "aa3c5b071234: Preparing\n",
      "e0c4197104f9: Preparing\n",
      "1fb2bc13bdda: Preparing\n",
      "9136ffbbf4aa: Preparing\n",
      "b3a9262c451e: Preparing\n",
      "ce70cf3f2428: Preparing\n",
      "2faed3426aa2: Preparing\n",
      "fee4cef4c353: Preparing\n",
      "dc657e1d2f27: Preparing\n",
      "588d3e4e8828: Preparing\n",
      "bf3d982208f5: Preparing\n",
      "1fb2bc13bdda: Waiting\n",
      "cd7b4cc1c2dd: Preparing\n",
      "3a0404adc8bd: Preparing\n",
      "9136ffbbf4aa: Waiting\n",
      "82718dbf791d: Preparing\n",
      "e0c4197104f9: Waiting\n",
      "b3a9262c451e: Waiting\n",
      "c8aa3ff3c3d3: Preparing\n",
      "ce70cf3f2428: Waiting\n",
      "dc657e1d2f27: Waiting\n",
      "cd7b4cc1c2dd: Waiting\n",
      "2faed3426aa2: Waiting\n",
      "588d3e4e8828: Waiting\n",
      "3a0404adc8bd: Waiting\n",
      "82718dbf791d: Waiting\n",
      "fee4cef4c353: Waiting\n",
      "bf3d982208f5: Waiting\n",
      "c8aa3ff3c3d3: Waiting\n",
      "cb97ce23f2f2: Pushed\n",
      "613ece60d6b2: Pushed\n",
      "ae040751a676: Pushed\n",
      "e0c4197104f9: Pushed\n",
      "9136ffbbf4aa: Pushed\n",
      "1fb2bc13bdda: Pushed\n",
      "b3a9262c451e: Pushed\n",
      "2faed3426aa2: Pushed\n",
      "dc657e1d2f27: Pushed\n",
      "aa3c5b071234: Pushed\n",
      "bf3d982208f5: Pushed\n",
      "cd7b4cc1c2dd: Pushed\n",
      "3a0404adc8bd: Pushed\n",
      "82718dbf791d: Pushed\n",
      "6b9c0da0c008: Pushed\n",
      "c8aa3ff3c3d3: Pushed\n",
      "ce70cf3f2428: Pushed\n",
      "588d3e4e8828: Pushed\n",
      "fee4cef4c353: Pushed\n",
      "latest: digest: sha256:41d8958007cf4298103ca997d6091606e9a16b479ceff42b54c13aa6f98a289b size: 4297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-tf-cifar10-example\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x cifar10/train\n",
    "chmod +x cifar10/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "# region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로컬 머신 (또는 SageMaker 노트북 인스턴스)에서 알고리즘 테스트 \n",
    "\n",
    "알고리즘을 처음 패키징할 때에는 여러분의 코드가 잘 동작하는지 테스트가 필요할 것입니다. [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk)를 이용하여 SageMaker환경 또는 로컬환경에서 이를 확인할 수 있습니다. SageMaker Python SDK와 관련한 더 많은 예제는 [Amazon SageMaker Examples](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk)를 참고합니다.\n",
    "\n",
    "이제 테스트를 위해 데이터셋을 준비합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 데이터셋 다운로드\n",
    "\n",
    "본 예제에서 Tensorflow 학습 실행시 레코드 기반의 이진 포맷인 [TFRecords](https://www.tensorflow.org/guide/datasets) 형식을 이용할 것입니다.\n",
    "다음 코드는 [official TensorFlow CIFAR-10 example](https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10_estimator) 공식 예제이며 CIFAR-10 데이터셋을 다운로드하고 TFRecord로 변환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "Download from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and extract.\n",
      "FloatProgress(value=0.0)\n",
      ">> Downloading cifar-10-python.tar.gz \n",
      "Successfully downloaded cifar-10-python.tar.gz 170498071 bytes.\n",
      "Generating /tmp/cifar-10-data/train.tfrecords\n",
      "WARNING:tensorflow:From utils/generate_cifar10_tfrecords.py:99: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From utils/generate_cifar10_tfrecords.py:88: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "Generating /tmp/cifar-10-data/validation.tfrecords\n",
      "Generating /tmp/cifar-10-data/eval.tfrecords\n",
      "Removing original files.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "! python utils/generate_cifar10_tfrecords.py --data-dir=/tmp/cifar-10-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval.tfrecords\ttrain.tfrecords  validation.tfrecords\r\n"
     ]
    }
   ],
   "source": [
    "# There should be three tfrecords. (eval, train, validation)\n",
    "! ls /tmp/cifar-10-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Python SDK 로컬 학습(trianing)\n",
    "\n",
    "학습을 진행하기 위해 Estimator를 선언하며 다음을 파라미터로 구성합니다.\n",
    "1. IAM role - AWS 실행 역할(role)\n",
    "2. train_instance_count - 학습에 사용할 인스턴스 개수 \n",
    "3. train_instance_type - 학습에 사용할 인스턴스 타입. 로컬에서 실행하려면 `local`로 입력함\n",
    "4. image_name - (앞 단계에서 생성한) 커스텀 TensorFlow 도커 이미지\n",
    "5. hyperparameters - 학습에 사용할 하이퍼파리미터들\n",
    "\n",
    "IAM 역할을 구성해보겠습니다. SageMaker Python SDK의 helper function을 이용합니다. 이 함수는 SageMaker 노트북 인스턴스로부터 메터정보를 얻기 때문에, SageMaker 노트북 환경이 아닌 경우 에러가 발생할 것입니다. SageMaker 노트북 환경이 아닌경우 적절한 권한을 가지는 역할을 지정합니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit, Deploy, Predict\n",
    "\n",
    "Estimator의 나머지 내용을 구성하고 `file://`로 시작하는 로컬 CIFAR10 데이터셋 경로를 이용하여 `fit()`을 호출합니다. 이제 SageMaker는 Tensorflow 컨테이너의 'train' 을 실행하면서 하이퍼파리미터와 다른 메타데이터들을 /opt/ml/input/config 경로로 전달할 것입니다.\n",
    "\n",
    "학습 작업이 성공적으로 종료되면, 알고리즘은 /opt/ml/model 디렉토리에 학습된 모델을 저장합니다. 이 모델은 예측에 이용될 것입니다.\n",
    "\n",
    "학습이후 instance_count와 instance_type을 각각 1과 `local`로 지정하고 `deploy()`를 호출합니다. SageMaker는 Tensorflow 컨테이너의 'serve'를 실행할 것입니다. serve 프로세스는 이제 Tensorflow serving을 통해 예측 요청을 처리하는 셋업을 컨테이너에 실행합니다. 'deploy'의 결과르 predictor라 리턴되며 이는 학습된 모델을 이용하여 추론을 하는 데 사용됩니다. \n",
    "\n",
    "예측이 끝난 후에는 엔드포인트를 삭제할 수 있습니다.\n",
    "\n",
    "이처럼 보다 빠른 피드백을 받으면서 디버깅을 할 수 있도록, 먼저 로컬환경에서 알고리즘을 테스트해볼 것을 추천합니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user has root access.\n",
      "nvidia-docker2 already installed. We are good to go!\n",
      "SageMaker instance route table setup is ok. We are good to go.\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\n"
     ]
    }
   ],
   "source": [
    "# Lets set up our SageMaker notebook instance for local mode.\n",
    "!/bin/bash ./utils/setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training(학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 869wbx0a5m-algo-1-t8grk ... \n",
      "Creating 869wbx0a5m-algo-1-t8grk ... done\n",
      "Attaching to 869wbx0a5m-algo-1-t8grk\n",
      "\u001b[36m869wbx0a5m-algo-1-t8grk |\u001b[0m Training complete.\n",
      "\u001b[36m869wbx0a5m-algo-1-t8grk exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "hyperparameters = {'train-steps': 100}\n",
    "\n",
    "instance_type = 'local'\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      instance_count=1,\n",
    "                      instance_type=instance_type,\n",
    "                      image_uri='sagemaker-tf-cifar10-example:latest',\n",
    "                      hyperparameters=hyperparameters)\n",
    "\n",
    "estimator.fit('file:///tmp/cifar-10-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment(추론)\n",
    "\n",
    "2020년 10월부터 SageMaker Python SDK가 v1에서 v2로 전면 변경되면서, 요청(request)과 응답(response)의 용법이 크게 변경되었습니다. 자세한 변경점은 아래 링크를 참조해 주십시오.\n",
    "- https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/upgrade_from_legacy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to h14g8h4f7a-algo-1-3i3vh\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m Starting TensorFlow Serving.\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.622246: I tensorflow_serving/model_servers/server.cc:88] Building single TensorFlow model file config:  model_name: cifar10_model model_base_path: /opt/ml/model/export/Servo\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.622441: I tensorflow_serving/model_servers/server_core.cc:464] Adding/updating models.\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.622467: I tensorflow_serving/model_servers/server_core.cc:587]  (Re-)adding model: cifar10_model\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.722810: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: cifar10_model version: 1616228549}\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.722844: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: cifar10_model version: 1616228549}\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.722866: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: cifar10_model version: 1616228549}\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.722919: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /opt/ml/model/export/Servo/1616228549\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.729973: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.730027: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /opt/ml/model/export/Servo/1616228549\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.730146: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.774137: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.779576: I external/org_tensorflow/tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2300065000 Hz\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.885399: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /opt/ml/model/export/Servo/1616228549\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.894359: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 171436 microseconds.\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.896228: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /opt/ml/model/export/Servo/1616228549/assets.extra/tf_serving_warmup_requests\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.897415: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: cifar10_model version: 1616228549}\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.900527: I tensorflow_serving/model_servers/server.cc:371] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m [warn] getaddrinfo: address family for nodename not supported\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 2021-03-20 08:26:17.902400: I tensorflow_serving/model_servers/server.cc:391] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m [evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n",
      "!\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 172.18.0.1 - - [20/Mar/2021:08:26:20 +0000] \"GET /ping HTTP/1.1\" 200 2 \"-\" \"python-urllib3/1.26.3\"\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "predictor = estimator.deploy(1, instance_type, serializer=JSONSerializer(), deserializer=JSONDeserializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python SDK로 추론 실행하기\n",
    "\n",
    "예측을 실행하기 위해 OpenCV를 이용하여 이미지를 json 형식으로 변환하여 사용하겠습니다. OpenCV를 설치합니다. \n",
    "\n",
    "JSON 응답 결과는 10개의 클래스 중 해당 사진이 속할 클래스의 확률을 리턴할 것입니다. 클래스는 다음 [CIFAR-10 website](https://www.cs.toronto.edu/~kriz/cifar.html) 링크를 참조합니다. 학습을 오래 실행하지는 않았으므로 아직 결과의 정확도는 떨어질 것입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (4.5.1.48)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from opencv-python) (1.18.5)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'probabilities': [0.00115666038,\n",
       "    0.905890524,\n",
       "    0.00990418904,\n",
       "    0.00254561636,\n",
       "    0.00637906278,\n",
       "    0.0192576591,\n",
       "    0.0019765608,\n",
       "    0.00477025565,\n",
       "    0.0402701311,\n",
       "    0.00784943439],\n",
       "   'classes': 1}]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mh14g8h4f7a-algo-1-3i3vh |\u001b[0m 172.18.0.1 - - [20/Mar/2021:08:26:31 +0000] \"POST /invocations HTTP/1.1\" 200 262 \"-\" \"python-urllib3/1.26.3\"\r\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "image = cv2.imread(\"data/cat.png\", 1)\n",
    "\n",
    "# resize, as our model is expecting images in 32x32.\n",
    "image = cv2.resize(image, (32, 32))\n",
    "data = {'instances': numpy.asarray(image).astype(float).tolist()}\n",
    "\n",
    "# For more information on the predictor class.\n",
    "# https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/predictor.py\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE                                 COMMAND             CREATED             STATUS                     PORTS                                        NAMES\r\n",
      "2667796ab8e0        sagemaker-tf-cifar10-example:latest   \"serve\"             17 seconds ago      Up 15 seconds              6006/tcp, 8888/tcp, 0.0.0.0:8080->8080/tcp   h14g8h4f7a-algo-1-3i3vh\r\n",
      "02823d3c317f        sagemaker-tf-cifar10-example:latest   \"train\"             4 minutes ago       Exited (0) 4 minutes ago                                                869wbx0a5m-algo-1-t8grk\r\n"
     ]
    }
   ],
   "source": [
    "!docker ps -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Amazon SageMaker에서 커스텀 알고리즘으로 학습과 추론 실행\n",
    "\n",
    "컨테이너 패키징이 완료되면 이제 SageMaker에서도 학습과 추론을 실행할 수 있습니다. 앞서 만든 알고리즘 컨테이너를 그대로 사용합니다. \n",
    "\n",
    "\n",
    "## 환경 셋업\n",
    "\n",
    "SageMaker에서 사용할 S3 버킷을 설정합니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, random\n",
    "string_pool = string.ascii_lowercase + string.ascii_uppercase + string.digits\n",
    "result = \"\" \n",
    "for i in range(8) : \n",
    "    result += random.choice(string_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO-tensorflow-cifar10-OHZGFSkc\n"
     ]
    }
   ],
   "source": [
    "# S3 prefix\n",
    "prefix = f'DEMO-tensorflow-cifar10-{result}'\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세션 생성\n",
    "\n",
    "세션은 SageMaker 환경에 대한 접속 파리미터를 기억합니다. 이후 SageMaker 동작에 이 세션을 사용할 것입니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습용 데이터 업로드\n",
    "\n",
    "SageMaker Python SDK에서 제공되는 도구를 이용하여 데이터를 디폴트 버킷에 업로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = '/tmp/cifar-10-data'\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker에서 학습(training)\n",
    "\n",
    "SageMaker에서의 학습은 Python SDK를 통해 실행할 수 있으며 local 환경에서 실행했던 방식과 거의 동일합니다. \n",
    "- 이전 단계에서 `local`로 지정했던 train_instance_type 을 [supported EC2 instance types](https://aws.amazon.com/sagemaker/pricing/instance-types/) 리스트중 하나로 변경하여 지정합니다. \n",
    "- 추가로, 이전 단계에서 ECR에 push했던 이미지 URL을 지정합니다. \n",
    "- 마지막으로, S3로 업로드한 학습 데이터셋의 S3 URL을 지정하여 `fit()` 을 호출합니다.\n",
    "\n",
    "다음 코드는 이전 단계에서 push한 ECR 이미지 URL을 먼저 가져오고 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143656149352.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tf-cifar10-example:latest\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "region = my_session.region_name\n",
    "\n",
    "algorithm_name = 'sagemaker-tf-cifar10-example'\n",
    "\n",
    "ecr_image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name)\n",
    "\n",
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training(학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-20 08:47:00 Starting - Starting the training job...\n",
      "2021-03-20 08:47:02 Starting - Launching requested ML instancesProfilerReport-1616230020: InProgress\n",
      "......\n",
      "2021-03-20 08:48:30 Starting - Preparing the instances for training......\n",
      "2021-03-20 08:49:30 Downloading - Downloading input data...\n",
      "2021-03-20 08:49:50 Training - Downloading the training image......\n",
      "2021-03-20 08:50:50 Training - Training image download completed. Training in progress....\n",
      "2021-03-20 08:51:30 Uploading - Uploading generated training model\n",
      "2021-03-20 08:51:30 Completed - Training job completed\n",
      "ProfilerReport-1616230020: NoIssuesFound\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "Training seconds: 121\n",
      "Billable seconds: 121\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "hyperparameters = {'train-steps': 100}\n",
    "\n",
    "instance_type = 'ml.m4.xlarge'\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      instance_count=1,\n",
    "                      instance_type=instance_type,\n",
    "                      image_uri=ecr_image,\n",
    "                      hyperparameters=hyperparameters)\n",
    "\n",
    "estimator.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment(추론)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!CPU times: user 290 ms, sys: 0 ns, total: 290 ms\n",
      "Wall time: 7min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "predictor = estimator.deploy(1, instance_type, serializer=JSONSerializer(), deserializer=JSONDeserializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'probabilities': [0.0128377527,\n",
       "    0.105647139,\n",
       "    0.0673772,\n",
       "    0.124453992,\n",
       "    0.138409868,\n",
       "    0.429724306,\n",
       "    0.0602907762,\n",
       "    0.0282724891,\n",
       "    0.0190955419,\n",
       "    0.0138909211],\n",
       "   'classes': 5}]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "image = cv2.imread(\"data/cat.png\", 1)\n",
    "\n",
    "# resize, as our model is expecting images in 32x32.\n",
    "image = cv2.resize(image, (32, 32))\n",
    "data = {'instances': numpy.asarray(image).astype(float).tolist()}\n",
    "\n",
    "# For more information on the predictor class.\n",
    "# https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/predictor.py\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 리소스 삭제(옵션)\n",
    "\n",
    "엔드포인트 사용이 완료되면 엔드포인트를 삭제합니다.\n",
    "\n",
    "생성한 모든 학습작업, 모델, 엔드포인트 는 SageMaker에 기록되었으며 AWS 콘솔을 통해 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "- [BYOC 가이드](https://github.com/gonsoomoon-ml/churn-prediction-workshop2/blob/master/BYOC/README.md)\n",
    "- [How Amazon SageMaker interacts with your Docker container for training](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html)\n",
    "- [How Amazon SageMaker interacts with your Docker container for inference](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html)\n",
    "- [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "- [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk)\n",
    "- [Dockerfile](https://docs.docker.com/engine/reference/builder/)\n",
    "- [scikit-bring-your-own](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
